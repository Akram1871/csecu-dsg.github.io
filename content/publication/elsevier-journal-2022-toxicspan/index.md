---
# Documentation: https://wowchemy.com/docs/managing-content/

title: "Leveraging fusion of sequence tagging models for toxic spans detection"
authors:
- Jannatun Naim
- Tashin Hossain
- Fareen Tasneem
- Abu Nowshed Chy 
author_notes:
- "Equal contribution"
- "Equal contribution"
- "Equal contribution"
date: 2022-12-16
doi: 

# Schedule page publish date (NOT publication's date).
publishDate: 2022-08-21T23:41:36Z

# Publication type.
# Legend: 0 = Uncategorized; 1 = Conference paper; 2 = Journal article;
# 3 = Preprint / Working Paper; 4 = Report; 5 = Book; 6 = Book section;
# 7 = Thesis; 8 = Patent
publication_types: ["2"]

# Publication name and optional abbreviated publication name.
publication: "Elsevier"
publication_short: "*Neurocomputing-2022*"
# **[On review]**
abstract: "The upsurge of prolific blogging and microblogging platforms enabled the abusers to spread negativity and threats greater than ever. Negative and hateful comments are averting users from sharing their opinion freely on social media platforms. It often breaks people’s confidence and causes extensive damage to their mental health. Hence, identifying these toxic contents and taking appropriate measures against them is crucial to preserve a safe environment on social media. Numerous state-of-the-art approaches classify the whole content as toxic or non-toxic, but they don’t distinguish the precise toxic portion from the whole content. Detecting the toxic portions is essential as it substantially aids to moderate the toxic contents through excluding the abusive parts. This paper describes our proposed approach to detect the toxic portions from text contents efficiently and accurately. We explore an ensemble of sequence labeling models including the word embedding-based Spark NLP NER (named entity recognition) deep learning model, spaCy NER model with custom toxic tags, and ALBERT NER model to identify the toxic spans. The NER-based models usually intend to capture the contextual attributes of phrases and spans that are essential for named entity recognition. As the toxic span detection task also requires us to apprehend the phrasal context for detecting toxic span, the similarity between these two tasks inspires us to exploit these NER models. Finally, we determine the final toxic spans using a prevalence-based fusion of the predictions generated by these models. The fusion strategy enables us to consolidate the diversity of these models for perceiving the phrasal context in all aspects. Experimental results achieved on the SemEval-2021 toxic spans detection dataset depict that our model meticulously captures the toxic fragment and achieves a competitive result among the other state-of-the-art methods."

# Summary. An optional shortened abstract.
summary: ""

tags: []
categories: []
featured: false

# Custom links (optional).
#   Uncomment and edit lines below to show custom links.
# links:
# - name: Follow
#   url: https://twitter.com
#   icon_pack: fab
#   icon: twitter

url_pdf: https://www.sciencedirect.com/science/article/abs/pii/S0925231222006166
url_code:
url_dataset:
url_poster:
url_project:
url_slides:
url_source:
url_video:

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder. 
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ""
  focal_point: ""
  preview_only: false

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `internal-project` references `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
projects: []

# Slides (optional).
#   Associate this publication with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides: "example"` references `content/slides/example/index.md`.
#   Otherwise, set `slides: ""`.
slides: ""
---
